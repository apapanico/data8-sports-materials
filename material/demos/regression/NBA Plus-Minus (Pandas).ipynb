{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plus/Minus Ratings\n",
    "\n",
    "We can approach evaluating a player in two ways:\n",
    "+ Using data on the events they generate like made shots, assists, etc\n",
    "+ Using the cumulative scoring while the player is on the court\n",
    "\n",
    "The basic Plus/Minus calculation is given by:\n",
    "\\begin{align}\n",
    "    \\text{Player Plus/Minus} \n",
    "        & = \\text{Team Points Scored w/ Player on Court} - \\text{Team Points Allowed w/ Player on Court} \\\\\n",
    "        & = \\text{Net Team Points w/ Player on Court}\n",
    "\\end{align}\n",
    "\n",
    "In theory, this should be an effective general measurement of a player that directly captures the effect on scoring.  Especially given that when we try to use player events, there are inevitably things we are missing that should impact scoring.  For instance, if a player doesn't register conventional boxscore stats but is a good player that helps overall scoring, Plus/Minus might be able to capture it.\n",
    "\n",
    "Unfortunately, it doesn't work out like this.  We'll see why and how to try to do better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../../utils/notebook_setup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from datascience_stats import multiple_regression_big"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Stint data\n",
    "\n",
    "Here we can see the data on all the stints but this isn't really effective for performing a regression analysis.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('nba_stints_2015_full.csv.gz')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stint Data for Regression\n",
    "\n",
    "Instead, we use encoded data that is actually numeric.  Each player is represented by a 0 or 1.  If a player is on the court during the stint, he will have a 1.  Most of the entries will be 0.\n",
    "\n",
    "HCA naturally stands for home court advantage and is actually just a column of 1s.  This is like fitting an intercept.\n",
    "\n",
    "\n",
    "We do this via a big model where each variable corresponds to a player and is 0 if the player was _not_ on the court during the stint and 1 if he was.  This creates a table of 0s and 1s of size Number of Stints by Number of Players + 1.  The +1 is for an extra variable representing the home court advantage.  Each row will only have 10 1s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stints = pd.read_csv('nba_stints_2015_binary.csv.gz')\n",
    "players = list(stints.loc[:, 'A.J. Price':].columns)\n",
    "\n",
    "stints.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Plus/Minus\n",
    "\n",
    "We can build the Plus/Minus for each player by summing up their net points for each time the player is on the court.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_plus_minus = {}\n",
    "for player in players:\n",
    "    # compute the plus minus value\n",
    "    plus_minus_val = (stints['home_netpts'] * stints[player]).sum()\n",
    "    player_plus_minus[player] = plus_minus_val\n",
    "    \n",
    "player_plus_minus = pd.Series(player_plus_minus).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the top players, we see a lot of famiilar names.  These are all starters or important players on the best teams in the league that year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_plus_minus.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we look at the bottom players, we see a lot young, not very good players who are also on weak teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_plus_minus.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Player Net Rating\n",
    "\n",
    "We should normalize by number of possessions.  This will help with evening out the players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_poss = {}\n",
    "for player in players:\n",
    "    # compute the number of possessions for the player\n",
    "    poss_ct = (stints['net_poss'] * stints[player].abs()).sum()\n",
    "    player_poss[player] = poss_ct\n",
    "    \n",
    "player_poss = pd.Series(player_poss).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_net_rtg = player_plus_minus / player_poss * 100\n",
    "player_net_rtg.sort_values(ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, it looks like some low possession players dominate because they did well in their few opportunities.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_net_rtg.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is beyond the scope of this demo (because the data isn't quite right) to take this a step further and compute the difference between the net rating when the player is on the court versus when the player is off the court."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Regression Plus/Minus\n",
    "\n",
    "We can think of a plus/minus rating as simultaneous impacts of players on team performance.  If we track performance over stints, where the same 10 players are on the court, we can measure a player's impact using a regression.\n",
    "\n",
    "The model is:\n",
    "\\begin{align}\n",
    "    \\mathrm{HomeNetRating}_t & = \\mathrm{HomeCourtAdv}\\ + \\\\\n",
    "    & \\quad \\mathrm{Sum}(\\mbox{Home Player $i$'s net rating if player $i$ is on the during the $t$-th stint})\\ - \\\\\n",
    "    & \\quad \\mathrm{Sum}(\\mbox{Away Player $i$'s net rating if player $i$ is on the during the $t$-th stint}).\n",
    "\\end{align}\n",
    "\n",
    "Using play-by-play data from 2014-15, the stint data is collected into a table.  For each stint, possessions and scoring is tracked as well as the 10 players on the court.  There are about 40k stints over this season."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusted Plus/Minus\n",
    "\n",
    "We need a more advanced solver for the regression model that can handle this much bigger problem.  This is where `multiple_regression_big` comes in.\n",
    "\n",
    "We set `net_rtg` as the dep_var and we set `HCA` and the players as the independent vars.  We also utilize weights: each stint has a total number of possessions.  We want the results from stints with more possessions to be weighted more than other possessions.\n",
    "\n",
    "After we compute the regression model, we can see some of the results that come out for the first ten players alphabetically.  These are the _Adjusted Plus/Minus_ or APM ratings\n",
    "\n",
    "The result of this regression model is a player rating which should indicate the impact the player had on Net Rating relative to league average.  A positive value obviously indicates a positive impact on Net Rating.  We could in fact use this to construct lineup net ratings above average by summing across a lineup of players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_var = 'home_netrtg'\n",
    "ind_vars = players\n",
    "\n",
    "# compute the regression for Net Rating\n",
    "apm = multiple_regression_big(dep_var, ind_vars, stints, constant=True)\n",
    "apm.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the histogram plot.\n",
    "\n",
    "This is odd... there are some very large values.  This is supposed to be the player's impact on net rating and there are values over 100 in magnitude??\n",
    "\n",
    "Did we do something wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apm.plot.hist(bins=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the top ranked players.\n",
    "\n",
    "Geez, who are some of these guys?  Where's Lebron??\n",
    "\n",
    "What happened?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apm_HCA = apm['Intercept']\n",
    "print(\"Home Court Advantage for Net Rating: {:.2f}\".format(apm_HCA))\n",
    "print()\n",
    "print(\"Top 20 by APM\\n\" + 40*\"=\")\n",
    "print(apm[players].sort_values(ascending=False)[:20].to_string())\n",
    "print()\n",
    "print(\"Bottom 20 by APM\\n\" + 40*\"=\")\n",
    "print(apm[players].sort_values(ascending=True)[:20].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Fixing the Regression Model\n",
    "\n",
    "The initial regression results are no good.  There a few issues:\n",
    "+ We didn't restrict to a minimum amount of playing time.  Malcolm Lee played like 1 stint which had an absurdly high Net Rating for his team.\n",
    "+ We're not addressing the issue of _multicolinearity_ which is basically the result of groups of the same players frequently playing together or players substituting at the same position and thus never playing together.\n",
    "\n",
    "\n",
    "We can try to fix the regression two ways:\n",
    "\n",
    "#### Weighting\n",
    "We can use weights so that instead of the squared error of each stint being treated equally, we'll emphasize stints with more possessions.  It's not always obvious there are weights to use but in this case, we should use the possessions as weights.  The more possessions, the more signal there is in the stint.\n",
    "\n",
    "#### Penalization\n",
    "This is more advanced but we can incorporate penalization when solving for the optimal model values.  The optimization of the model, ie. minimizing the squared error, is being overly aggressive in how it computes its values.  The result is an overfit model that won't generalize well.  \n",
    "\n",
    "Giving Malcolm Lee a high rating would do well to minimize the squared error but if we had a chance to observe him play more stints, the high rating would very soon appear to look like a very bad prediction, ie. it wouldn't generalize to other data.\n",
    "\n",
    "Penalizing the model's values reduces the overfitting by not allowing it to assign large values unless it really needs to.  If a player is going to be rated high, there needs to be a lot of observations so that high rating would contribute well to minimizing the error, moreso than the penalty we place on the rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Weights\n",
    "\n",
    "We can incorporate the number of possessions in the stint into the model very easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_var = 'home_netrtg'\n",
    "ind_vars = players\n",
    "weights = 'net_poss'\n",
    "\n",
    "# compute the weighted regression for Net Rating\n",
    "apm_weighted = multiple_regression_big(\n",
    "    dep_var, ind_vars, stints, weights=weights, constant=True)\n",
    "apm_weighted.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the histogram shows the results of the regression already appear to be better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apm_weighted.plot.hist(bins=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the ranking coming from the weighted regression.  First we'll create a complete dataframe with all the ratings so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "player_df = pd.DataFrame({\n",
    "    'Net Rating': player_net_rtg, \n",
    "    'APM': apm[players], \n",
    "    'Weighted APM': apm_weighted[players]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weighted regression is vastly superior to the regular regression model.  Comparing between the weighted model and raw net rating, we see that there is quite a bit of difference.  For instance, the weighted model likes DeMarcus Cousins a lot more than his net rating does, quite possibly due to the fact that Cousins played for the Kings, a notoriously trash team that could have tanked his rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apm_weighted_HCA = apm_weighted['Intercept']\n",
    "print(\"Home Court Advantage for Net Rating: {:.2f}\".format(apm_weighted_HCA))\n",
    "print()\n",
    "print(\"Top 20 by Weighted APM\\n\" + 40*\"=\")\n",
    "print(player_df.sort_values('Weighted APM', ascending=False).head(20).to_string())\n",
    "print()\n",
    "print(\"Bottom 20 by Weighted APM\\n\" + 40*\"=\")\n",
    "print(player_df.sort_values('Weighted APM', ascending=True).head(20).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penalizing the Least Squares Fit: Regularized Adjusted Plus Minus (xRAPM)\n",
    "\n",
    "We just ran into a few issues:\n",
    "+ Players who we should have dropped due to not having many minutes.  If they have a raw net rating of 200 in 1 possession, the regression will still try to aggressively optimize and give that player a high rating.  We can bucket those players together or force the regression optimizer to not be so aggressive\n",
    "+ Lineups do not behave like randomized controlled trials.  Given nine players on the court, we can do a really good job predicting the tenth.  Sometimes two players almost always play together.  Or two players switch for each other.\n",
    "+ This lack of randomization leads to a condition called _multicollinearity_ and is a huge potential problem in multiple regression problems.  Due to issues that can be derived/explained with Linear Algebra, if multicollinearity is present the regression will likely falter and not be able to distinguish well what is happening.  \n",
    "\n",
    "Our solution is to use something called _penalization_ or _regularization_.\n",
    "\n",
    "Instead of just aggressively minimizing the mean square error, we reframe the regression to simultaneously minimize mean square error but penalize aggressive fitting by the optimizer.  If the optimization wants to assign a big rating value to a player, it better have a lot of evidence behind it, ie. the reduction in the least squares needs to offset the penalty imposed.\n",
    "\n",
    "What exactly is the penalty?  We penalize the sum of squares of the coefficients and we introduce a penalty parameter that quantifies the strength of this penalty.  This parameter is our choice but there are methods (beyond the scope of this demo) that can suggest a good value.\n",
    "\n",
    "The result of this is a statistic attributed to Jerry Engelmann called _Regularized Adjusted Plus Minus_ or xRAPM.  It is actually the cousin/basis for ESPN's Real Plus/Minus statistic. \n",
    "\n",
    "We use a new function to perform this: `multiple_regression_big_with_penalty`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience_stats import multiple_regression_big_with_penalty\n",
    "\n",
    "dep_var = 'home_netrtg'\n",
    "ind_vars = players\n",
    "\n",
    "rapm = multiple_regression_big_with_penalty(\n",
    "    dep_var, ind_vars, stints, constant=True, penalty=800.)\n",
    "rapm.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks way better.  Now we see the people we expect to see at the top.  There are some interesting names at the top like Kyle Korver or Draymond Green.  I would have expected Draymond to rank high on defense but not overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rapm.plot.hist(bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rapm_HCA = rapm['Intercept']\n",
    "\n",
    "player_df['RAPM'] = rapm[players]\n",
    "print(\"Home Court Advantage for Net Rating: {:.2f}\".format(rapm_HCA))\n",
    "print()\n",
    "print(\"Top 20 by RAPM\\n\" + 40*\"=\")\n",
    "print(player_df.sort_values('RAPM', ascending=False).head(20).to_string())\n",
    "print()\n",
    "print(\"Bottom 20 by RAPM\\n\" + 40*\"=\")\n",
    "print(player_df.sort_values('RAPM', ascending=True).head(20).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Weighting and Penalization\n",
    "\n",
    "We can actually combine the two methods to achieve something pretty solid.\n",
    "\n",
    "A few comments:\n",
    "+ Note how the penalty parameter is a lot different now.  The weighting already picked up some slack so the penalty parameter doesn't have to do as much.\n",
    "+ Note how some players look a lot better with the weighting (Kelley Olynyk, Danny Green, George Hill) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapm = multiple_regression_big_with_penalty(\n",
    "    dep_var, ind_vars, stints, weights=weights, constant=True, penalty=0.001)\n",
    "\n",
    "wrapm.plot.hist(bins=50)\n",
    "\n",
    "wrapm_HCA = rapm['Intercept']\n",
    "player_df['wRAPM'] = wrapm[players]\n",
    "print(\"Home Court Advantage for Net Rating: {:.2f}\".format(wrapm_HCA))\n",
    "print()\n",
    "print(\"Top 20 by wRAPM\\n\" + 40*\"=\")\n",
    "print(player_df.sort_values('wRAPM', ascending=False).head(20).to_string())\n",
    "print()\n",
    "print(\"Bottom 20 by wRAPM\\n\" + 40*\"=\")\n",
    "print(player_df.sort_values('wRAPM', ascending=True).head(20).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to ESPN's RPM\n",
    "\n",
    "We can compare our results ESPN's Real Plus/Minus statistic.\n",
    "\n",
    "Compared against overall RPM from 2014-15, our rating is actually that not that bad.  We're overrating players a bit and maybe using more years would help.  RPM actually uses box score data and some biographic data to help stabilize the regression further.  We are working purely with lineup data so if they are doing things well, that extra data will improve things for them.\n",
    "\n",
    "Also note that ESPN produces Offensive RPM and Defensive RPM. To do this, we need to break up the stint data into offense and defense performance and have _two_ effects for each player, one for offense and one for defense.\n",
    "\n",
    "They also convert RPM to Wins, presumably using something like the pythagorean expectation formula.  Kevin Pelton's WARP statistic does similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpm = pd.read_csv('rpm.csv', index_col='RK')\n",
    "rpm"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
