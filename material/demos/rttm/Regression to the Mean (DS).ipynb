{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression to the Mean: Student Scores and Talent\n",
    "\n",
    "_Regression to the Mean_ is a statistical feature of data where future observations tend to not be as extreme as previous observations.  That is, we say extreme observations will regress towards the mean in the future.  This phenomenon shows up everywhere from team records to individual performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../../utils/notebook_setup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "\n",
    "import datascience as ds\n",
    "from datascience import Table\n",
    "from datascience_stats import linear_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Student Talent\n",
    "A simple example can be demonstrated through simulation.  Suppose we have 1,000 students take two tests.  The tests are designed to measure the underlying talent of the student.\n",
    "\n",
    "Student talent is normally distributed centered at 50 and with standard deviation 5.  A histogram of the talent distribution is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2027)\n",
    "n = 1000\n",
    "\n",
    "student_talents = np.random.normal(50, 5, size=n)\n",
    "plt.hist(student_talents);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Scores\n",
    "The tests are noisy measurements of the student talent: a talented student will tend to score well but the score can fluctuate.  We model the test performance as Normally distributed with mean 0 and a standard deviation we will vary.\n",
    "\n",
    "We start with a standard deviation of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_score = 2\n",
    "scores1 = student_talents + np.random.normal(0, std_score, size=n)\n",
    "scores2 = student_talents + np.random.normal(0, std_score, size=n)\n",
    "scores = Table().with_columns(['scores1', scores1, 'scores2', scores2])\n",
    "\n",
    "scores.scatter('scores1', select='scores2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Regression Prediction for Test 2 Scores\n",
    "\n",
    "Since there isn't too much noise in the tests, the tests do a decent job of measuring the performance and the test scores are obviously strongly correlated through the underlying student talent.\n",
    "\n",
    "Suppose we had a new set of students and administered the first test.  If we want a prediction for a score on the second test, we can use the above data to build a model through linear regression.\n",
    "\n",
    "\\begin{align*}\n",
    "    \\text{Test 2 Score} & = \\alpha + \\beta \\times \\text{Test 1 Score} \\\\\n",
    "        & = \\alpha + \\beta \\times (\\text{Test 1 Score} - \\text{Test 1 Avg} + \\text{Test 1 Avg}) \\\\\n",
    "        & =  (\\alpha + \\beta \\times \\text{Test 1 Avg}) + \\beta \\times (\\text{Test 1 Score} - \\text{Test 1 Avg}) \\\\\n",
    "    & = \\tilde{\\alpha} + \\beta \\times (\\text{Test 1 Score} - \\text{Test 1 Avg})\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, _, _ = linear_fit(scores1, scores2, constant=True)\n",
    "intercept, slope = params\n",
    "\n",
    "alpha = intercept\n",
    "alpha_tilde = intercept + slope * np.mean(scores1)\n",
    "beta = slope\n",
    "\n",
    "print(f\"Avg Score 1: {np.mean(scores1):.3f}\")\n",
    "print(f\"Avg Score 2: {np.mean(scores2):.3f}\")\n",
    "print()\n",
    "print(f\"alpha: {alpha:.3f}  alpha_tilde: {alpha_tilde:.3f}  beta: {beta:.3f}\")\n",
    "print(f\"Predicted Score 2 = {beta:.3f} x (Score 1) + {alpha:.3f}\")\n",
    "print(f\"Predicted Score 2 = {beta:.3f} x (Score 1 - Avg Score) + {alpha_tilde:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the regression model, the predicted score should not be score on Test 1.  Instead, the predicted score for Test 2 should be closer to the mean (about 50) than the observed score on Test 1.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Larger Standard Deviation of Scores\n",
    "\n",
    "What happens if the test scores are noisier?  We can increase the standard deviation of the scores to see what happens.\n",
    "\n",
    "If we compare this model to the previous model that had less noise, we see that the model values the score from Test 1 less (smaller slope coefficient) and therefore predictions are even closer to the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_score = 5\n",
    "scores1 = student_talents + np.random.normal(0, std_score, size=n)\n",
    "scores2 = student_talents + np.random.normal(0, std_score, size=n)\n",
    "scores = Table().with_columns(['scores1', scores1, 'scores2', scores2])\n",
    "\n",
    "scores.scatter('scores1', select='scores2')\n",
    "\n",
    "params, _, _ = linear_fit(scores1, scores2, constant=True)\n",
    "intercept, slope = params\n",
    "\n",
    "print(f\"Avg Score 1: {np.mean(scores1):.3f}\")\n",
    "print(f\"Avg Score 2: {np.mean(scores2):.3f}\")\n",
    "print(f\"Predicted Score 2 = {slope:.3f} x (Score 1) + {intercept:.3f}\")\n",
    "print(f\"Predicted Score 2 = {slope:.3f} x (Score 1 - Avg Score) + {intercept + slope * np.mean(scores1):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we go extreme and have a ridiculously large standard deviation of scores, the model basically does not care what the score is on Test 1 and will mainly just predict the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_score = 20\n",
    "scores1 = student_talents + np.random.normal(0, std_score, size=n)\n",
    "scores2 = student_talents + np.random.normal(0, std_score, size=n)\n",
    "scores = Table().with_columns(['scores1', scores1, 'scores2', scores2])\n",
    "\n",
    "scores.scatter('scores1', select='scores2')\n",
    "\n",
    "params, _, _ = linear_fit(scores1, scores2, constant=True)\n",
    "intercept, slope = params\n",
    "\n",
    "print(f\"Avg Score 1: {np.mean(scores1):.3f}\")\n",
    "print(f\"Avg Score 2: {np.mean(scores2):.3f}\")\n",
    "print(f\"Predicted Score 2 = {slope:.3f} x (Score 1) + {intercept:.3f}\")\n",
    "print(f\"Predicted Score 2 = {slope:.3f} x (Score 1 - Avg Score) + {intercept + slope * np.mean(scores1):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small Score Standard Deviation\n",
    "\n",
    "If we go the other way, we see that the score on Test 1 is highly predictive of the score on Test 2 and the model will more or less just use the Test 1 score as the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_score = .01\n",
    "scores1 = student_talents + np.random.normal(0, std_score, size=n)\n",
    "scores2 = student_talents + np.random.normal(0, std_score, size=n)\n",
    "scores = Table().with_columns(['scores1', scores1, 'scores2', scores2])\n",
    "\n",
    "scores.scatter('scores1', select='scores2')\n",
    "\n",
    "params, _, _ = linear_fit(scores1, scores2, constant=True)\n",
    "intercept, slope = params\n",
    "\n",
    "print(f\"Avg Score 1: {np.mean(scores1):.3f}\")\n",
    "print(f\"Avg Score 2: {np.mean(scores2):.3f}\")\n",
    "print(f\"Predicted Score 2 = {slope:.3f} x (Score 1) + {intercept:.3f}\")\n",
    "print(f\"Predicted Score 2 = {slope:.3f} x (Score 1 - Avg Score) + {intercept + slope * np.mean(scores1):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression to the Mean\n",
    "\n",
    "The above models demonstrate the concept of _Regression to the Mean_.  \n",
    "\n",
    "Our regression models were given as:\n",
    "$$\n",
    "    \\text{Test 2 Score} = \\hat\\alpha + \\hat\\beta \\cdot \\text{Test 1 Score}\n",
    "$$\n",
    "\n",
    "The formulas for the coefficients are:\n",
    "$$\n",
    "    \\hat\\alpha = \\text{Test 2 Avg} - \\hat\\beta\\cdot \\text{Test 1 Avg}\n",
    "$$\n",
    "and,\n",
    "$$\n",
    "    \\hat\\beta = \\mathrm{Corr}(\\text{Test 1 Score}, \\text{Test 2 Score})\\cdot \\frac{\\text{Std Test 2 Score}}{\\text{Std Test 1 Score}}\n",
    "$$\n",
    "\n",
    "Plugging in, we get\n",
    "$$\n",
    "    \\text{Test 2 Score} = \\text{Test 2 Avg} + \\hat\\beta\\cdot\\left(\\text{Test 1 Score} - \\text{Test 1 Avg} \\right)\n",
    "$$\n",
    "\n",
    "If our two test scores feature a similar standard deviation, then the driver of the slope $\\hat\\beta$ is the correlation between the two scores.  And the driver of the correlation of the test scores is the overall magnitude of the standard deviations of the test scores.\n",
    "\n",
    "The term Regression to the Mean comes from the fact that our predicted values will be closer to the mean than the observed values due to the fact that $\\hat\\beta$ is less than 1.  Multiplication by $\\hat\\beta$ is how we regress observations towards the mean.\n",
    "\n",
    "In general, regression to the mean will entail building an estimate of the form\n",
    "$$\n",
    "    \\text{Regressed Estimate} = w \\cdot \\text{Observation} + (1 - w) \\cdot \\text{Mean}\n",
    "$$\n",
    "where $w$ is between 0 and 1.  For $w$ close to 1, we do not regress much because we think the observation is more important.  For $w$ close to 0, we regress a lot because we think the noise in the observation renders it not informative and the mean is a better guess."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell should help convince you that the order of the regression (predicting Test 2 from Test 1) doesn't matter.  In general, predictions should not be as far from the mean as the observations.\n",
    "\n",
    "For more on this, see Sec 15.2 of Inferential Thinking: https://www.inferentialthinking.com/chapters/15/2/regression-line.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_score = 5\n",
    "scores1 = student_talents + np.random.normal(0, std_score, size=n)\n",
    "scores2 = student_talents + np.random.normal(0, std_score, size=n)\n",
    "scores = Table().with_columns(['scores1', scores1, 'scores2', scores2])\n",
    "\n",
    "scores.scatter('scores1', select='scores2')\n",
    "\n",
    "# Flip the variables and regress scores1 onto scores2\n",
    "params, _, _ = linear_fit(scores2, scores1, constant=True)\n",
    "intercept, slope = params\n",
    "\n",
    "print(f\"Avg Score 1: {np.mean(scores1):.3f}\")\n",
    "print(f\"Avg Score 2: {np.mean(scores2):.3f}\")\n",
    "print(f\"Predicted Score 1 = {slope:.3f} x (Score 2) + {intercept:.3f}\")\n",
    "print(f\"Predicted Score 1 = {slope:.3f} x (Score 2 - Avg Score) + {intercept + slope * np.mean(scores2):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Updating Beliefs\n",
    "\n",
    "At first, this section might appear to be unrelated.  But we will see how we can relate the concept of prior belief, updates, and Bayesian thinking with regression to the mean.\n",
    "\n",
    "We're going to do some coin tossing.  Our coin will have a probability $p$ of coming up heads.  We don't know $p$ and we're going to try to come up with an estimate for $p$.\n",
    "\n",
    "`CoinFlipper` is a class that will help us flip the coins and keep track of the results and make some handy plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience_topic import CoinFlipper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Opinion on $p$\n",
    "\n",
    "The coin has some random probability of coming up heads that we don't know so we might as well start tossing the coin to get a read on what $p$ could be.  If it's large, we should see a lot of heads.  If it's small, a lot of tails.  There's only one way to find out though.\n",
    "\n",
    "Before we do this, we can take a poll for what people _think_ the probability is.  As we toss the coin, we'll keep asking for guesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a flipper object\n",
    "flipper = CoinFlipper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "flipper.toss_coin(n=n)\n",
    "flipper.report()\n",
    "flipper.plot_tosses(figsize=(6,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what was $p$?  And how many heads did we expect to see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flipper.p, flipper.p * flipper.num_tosses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolving Distribution of Belief\n",
    "\n",
    "Since I didn't say anything about $p$ at the start, our initial belief about $p$ was flat or uninformed.  We model this through two simple parameters: $\\text{Expected Heads}$ and $\\text{Expected Tails}$, or just $H$ and $T$ for short.  Our flat, indifferent, agnostic, or uninformed belief is given by $H=1$ and $T=1$.  Or _best guess_ is the mean of the belief distribution which is given by the formula\n",
    "$$\n",
    "    \\text{Best Guess for $p$} = \\frac{H}{H + T}\n",
    "$$\n",
    "For $H=T=1$, our best guess is $p = \\frac12$.\n",
    "\n",
    "We call it the best guess because it will minimize expected error based on whatever $p$ may be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipper = CoinFlipper(expected_heads=1, expected_tails=1)\n",
    "flipper.report(report_belief=True)\n",
    "flipper.plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tossing Coins and Updating the Belief Distribution\n",
    "\n",
    "As we toss the coin, we use the observations of heads and tails to update our beliefs.  The updating formula is very simple:\n",
    "$$\n",
    "    H_{new} = H_{old} + \\text{Number of Heads tossed},\\quad T_{new} = T_{old} + \\text{Number of Tails tossed}\n",
    "$$\n",
    "\n",
    "Our updated best guess is:\n",
    "\\begin{align*}\n",
    "    \\text{Updated Best Guess for $p$} \n",
    "        & = \\frac{H_{new}}{H_{new} + T_{new}} \\\\\n",
    "        & = \\frac{H_{old} + \\text{Number of Heads tossed}}\n",
    "        {H_{old} + \\text{Number of Heads tossed} + T_{old} + \\text{Number of Tails tossed}}\\\\\n",
    "        & = \\frac{H_{old} + \\text{Number of Heads tossed}}\n",
    "        {H_{old} + T_{old} + \\text{Number of tosses}}\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100000\n",
    "flipper.toss_coin(n=n)\n",
    "flipper.report(report_belief=True)\n",
    "flipper.plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stronger Prior Beliefs\n",
    "\n",
    "We do not have to start with a flat, uninformed prior.  We may know something about our coin!\n",
    "\n",
    "Below, we start with $H=73$ and $T=210$.  We take $p=.370$ so that we can see how things behave more specifically.\n",
    "\n",
    "So what does it mean that $H=73$ and $T=210$?  Well, for one, our initial best guess for $p$ (if we didn't know it)  without any coin tosses is \n",
    "$$\n",
    "    \\text{Initial Best Guess} = \\frac{73}{283} = 0.258\n",
    "$$\n",
    "So $H$ and $T$ encode where the center of the distribution is (.258).  It also encodes the shape, ie. how tight around the center the distribution is.  Large values of $H$ and $T$ mean we have stronger beliefs and therefore a tighter distribution.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipper = CoinFlipper(expected_heads=75, expected_tails=215, p=.370)\n",
    "flipper.report(report_belief=True)\n",
    "flipper.plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we make observations, our best guess will have the formula,\n",
    "$$\n",
    "    \\text{Best Guess after $N$ tosses} = \\frac{73 + \\text{Number of Heads}}{283 + N}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 600\n",
    "flipper.toss_coin(n=n)\n",
    "flipper.report(report_belief=True)\n",
    "flipper.plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Guess and Regression to the Mean\n",
    "\n",
    "Let's look closer at the formula for the best guess:\n",
    "$$\n",
    "    \\text{Best Guess after $N$ tosses} = \\frac{H_{initial} + \\text{Number of Heads}}{H_{initial} + T_{initial} + N}\n",
    "$$\n",
    "\n",
    "With a little algebra, we get:\n",
    "$$\n",
    "    \\text{Best Guess after $N$ tosses} \n",
    "        = \\frac{N}{H_{initial} + T_{initial} + N}\\cdot\\frac{\\text{Number of Heads}}{N} \n",
    "        + \\frac{H_{initial} + T_{initial}}{H_{initial} + T_{initial} + N}\\cdot\\frac{H_{initial}}{H_{initial} + T_{initial}}\n",
    "$$\n",
    "Or...\n",
    "\\begin{gather*}\n",
    "    \\text{Best Guess after $N$ tosses}\n",
    "        = w_N \\cdot \\text{Proportion of Heads observed} + (1 - w_N) \\cdot \\text{Initial Best Guess}\\\\\n",
    "    w_N = \\frac{N}{H_{initial} + T_{initial} + N}\n",
    "\\end{gather*}\n",
    "Note that $w_N$ is between 0 and 1.\n",
    "\n",
    "This is precisely a formula for regression to the mean!  The mean is our initial best guess and we \"regress\" our observed frequency towards the mean.  As we observe more and more data though, we regress less and less because $w_N$ gets closer and closer to 1 as $N$ grows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_N = 10000 / (75 + 215 + 10000)\n",
    "w_N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beta Belief Distribution\n",
    "\n",
    "So far, we haven't said anything about what this belief distribution is.  It's actually known as a Beta distribution and the function plotted above has the form,\n",
    "$$\n",
    "    K \\cdot x^{H - 1} \\cdot (1 - x)^{T - 1}\n",
    "$$\n",
    "where $K$ is just a constant that ensures the integral of the function from 0 to 1 equals 1.  \n",
    "\n",
    "The parameters $H$ and $T$ (also often labeled as $a$ and $b$ instead) clearly govern the location of the center of the distribution as well as the shape.  And as they increase, create a tighter distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 1, 1000)\n",
    "H = 1000\n",
    "T = 200\n",
    "plt.plot(x, x**(H - 1) * (1 - x)**(T - 1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Regression to the Mean, Baseball, and Batting Average\n",
    "\n",
    "Let's apply the above to baseball and projecting a player's batting average after only a few at-bats.\n",
    "\n",
    "We load the Lahman tables as usual.  The hardest part is we need to build an initial guess for batting average that will serve as the mean we will regress towards.  Here is how we will do that:\n",
    "\n",
    "1. Collect historical data on players and their career batting averages.\n",
    "2. Filter out pitchers and other batters who did not bat much\n",
    "3. Estimate $H$ and $T$ from the historical data.\n",
    "4. Use the estimated $H$ and $T$ to form a regressed estimate of batting average.  This is an _Empirical Bayes_ estimation of the estimated batting average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Lahman Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lahman_bat = Table.read_table('lahman_batting.csv') \n",
    "lahman_bat['PA'] = lahman_bat['AB'] + lahman_bat['BB'] + lahman_bat['HBP'] + \\\n",
    "    lahman_bat['SF'] + lahman_bat['SH']\n",
    "lahman_pitch = Table.read_table('lahman_pitching.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lahman_bat.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Career Totals\n",
    "\n",
    "For batters, we compute total hits and at-bats.  For pitchers, we compute total batters faced (`BFP`).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batting_totals = lahman_bat.select('playerID', 'H', 'AB').\\\n",
    "    group('playerID', collect=sum).\\\n",
    "    relabel('H sum', 'H').\\\n",
    "    relabel('AB sum', 'AB')\n",
    "pitching_totals = lahman_pitch.select('playerID', 'BFP').\\\n",
    "    group('playerID', collect=sum).\\\n",
    "    relabel('BFP sum', 'Batters Faced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to know who the pitchers are because they can grossly distort how we view the distribution of batting averages.  The histogram shows just how messy the raw batting averages are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batting_totals['BA'] = batting_totals['H'] / (batting_totals['AB'] + 1)  # add 1 AB so we don't divide by 0\n",
    "batting_totals.hist('BA', bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Pitchers and Batters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience_utils import merge\n",
    "\n",
    "merged_players = merge(batting_totals, pitching_totals, 'playerID', how='outer', fillna=True)\n",
    "merged_players.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Pitchers\n",
    "We figure out who the batters are by taking anyone with more at-bats and batters faced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_AB_than_BFP = merged_players['AB'] > merged_players['Batters Faced']\n",
    "batters = merged_players.where(more_AB_than_BFP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take Batters with at least 500 AB\n",
    "\n",
    "We want a more stable notion of batting average so we need to restrict to batters with a minimum number of AB.  500 is probably good enough since that represents about 1 season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batters_500AB = batters.where('AB', ds.are.above_or_equal_to(500))\n",
    "batters_500AB.hist('BA', bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Belief Distribution\n",
    "\n",
    "The function `fit_beta_belief` can take in observed frequencies/rates and fit the Beta belief distribution.  The function `plot_beta_belief` can plot the belief distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience_topic import fit_beta_belief, plot_beta_belief, plot_beta_belief_and_batting_avg\n",
    "\n",
    "H, T = fit_beta_belief(batters_500AB['BA'])\n",
    "plot_beta_belief(H, T)\n",
    "H, T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does our fitted distribution compare to the historical data on batting average?  The helper function `plot_beta_belief_and_batting_avg` can take care of that.\n",
    "\n",
    "It looks like a pretty great fit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_beta_belief_and_batting_avg(H, T, batters_500AB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Returning to the CoinFlipper\n",
    "\n",
    "We can use the coin flipper to explore how our belief updates and how we regress to the mean after a few at-bats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipper = CoinFlipper(expected_heads=H, expected_tails=T, p=.370)\n",
    "flipper.report(report_belief=True)\n",
    "flipper.plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipper.toss_coin(n=20)\n",
    "flipper.report(report_belief=True)\n",
    "flipper.plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projections: Marcel the Monkey\n",
    "\n",
    "How can we use regression to the mean for the purposes of projecting statistics in an upcoming season?  Tom Tango's very simple projection system, Marcel, is a great way to explore how to use recency weighting and regression to the mean to build a projection.\n",
    "\n",
    "And despite the relatively lack of complexity, it apparently performs pretty well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projecting Mike Trout's HRs\n",
    "\n",
    "The best way to learn the Marcel system is to walk through the computation.  Let's pull up Mike Trout's data and forecast his HRs for 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trout = lahman_bat.where('playerID', 'troutmi01')\n",
    "trout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HRs and PAs\n",
    "\n",
    "In order to forecase Mike Trout's HRs, we need his PAs and HRs for the last three seasons.  For each of those seasons, we compute his HR rate as $\\mathit{HR} / \\mathit{PA}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trout_HRs_last3 = trout['HR'][-3:]\n",
    "trout_PAs_last3 = trout['PA'][-3:]\n",
    "trout_HRrate_last3 = trout_HRs_last3 / trout_PAs_last3\n",
    "trout_HRs_last3, trout_PAs_last3, trout_HRrate_last3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recency Weighting\n",
    "\n",
    "Marcel uses recency weighting to base the projection on performance from the player.  The weights for the previous three seasons, from oldest to most recent, are given below.\n",
    "\n",
    "These weightings are the modeller's discretion and Tango does not offer too much insight other than it seems to work well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marcel_weights = np.array([3, 4, 5]) / 12\n",
    "marcel_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trout's Weighted Average HR Rate and PA\n",
    "\n",
    "We want to compute Mike Trout's average HR rate and average PA over the last three years.  But we use the Marcel weights to create the recency weighting.  We also need to weight the relevance by how many PAs Mike Trout had in each season.  Last season, he had many fewer PAs so even though it's the most recent, it needs to be downgraded in importance due to it being a relatively smaller sample.\n",
    "\n",
    "$$\n",
    "    \\text{Weighted Avg PA} = \\sum_{year} \\text{PA}_{year} \\cdot \\text{Marcel Weight}_{year}\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\text{Weighted Avg HR Rate} = \\sum_{year} \\frac{\\text{PA}_{year}}{\\text{Weighted Avg PA}} \\cdot \\text{HR Rate}_{year} \\cdot \\text{Marcel Weight}_{year}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trout_weighted_avg_PA = np.sum(trout_PAs_last3 * marcel_weights)\n",
    "trout_weighted_avg_PA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_year_weight = trout_PAs_last3 / trout_weighted_avg_PA\n",
    "pa_year_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trout_weighted_HRrate = np.sum(trout_HRrate_last3 * marcel_weights * pa_year_weight)\n",
    "trout_weighted_HRrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### League Averages\n",
    "\n",
    "The league average HR rate was computed offline separately.  The values are given below.\n",
    "\n",
    "We need to compare Trout to a league average player given the same opportunity as Trout had.  We thus use the same PA weightings but swap out Trout's HR rates for the league average rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_avg_HRrate = np.array([ 0.02740387,  0.0311592 ,  0.03376997])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_avg_weighted_HRrate = np.sum(lg_avg_HRrate * marcel_weights * pa_year_weight)\n",
    "lg_avg_weighted_HRrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression to the Mean Formula\n",
    "\n",
    "The regresion to the mean formula is simple and one we recognize from above:\n",
    "$$\n",
    "    \\text{Marcel Projection} = w \\cdot \\text{Trout Weighted HR Rate} +\n",
    "        (1 - w) \\cdot \\text{League Avg Weighted HR Rate}\n",
    "$$\n",
    "\n",
    "Tango calls the quantity $w$ _reliability_.  The formula for reliability is simple:\n",
    "$$\n",
    "    w = \\frac{\\text{Trout Weighted Avg PA}}{\\text{Trout Weighted Avg PA} + 100}\n",
    "$$\n",
    "If we think about this from our Beta Belief distribution, Tango's reliability is based on a prior belief that $H + T = 100$.\n",
    "\n",
    "It turns out that this is same formula for any statistic in the Marcel system.  A natural extension would be the hone the quantities $a$ and $b$ to achieve better regression to the mean performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = trout_weighted_avg_PA / (trout_weighted_avg_PA + 100)\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trout's HR Rate Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trout_HRrate_projection = w * trout_weighted_HRrate + \\\n",
    "    (1 - w) * lg_avg_weighted_HRrate\n",
    "trout_HRrate_projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projecting PA\n",
    "\n",
    "To get a HR projection, we need a PA projection.  Tango offers up a simple formula:\n",
    "$$\n",
    "    \\text{Projected PA} = .5 \\cdot \\text{Previous Year's PA} + .1 \\cdot \\text{Second Previous Year's PA} + 200\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PA_proj_weights = np.array([0., .1, .5])\n",
    "trout_PA_projection = np.sum(trout_PAs_last3 * PA_proj_weights) + 200\n",
    "trout_PA_projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trout's Raw HR Total Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trout_HR_projection = trout_HRrate_projection * trout_PA_projection\n",
    "trout_HR_projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age Adjustment\n",
    "\n",
    "Tango includes a rudimentary age adjustment:\n",
    "$$\n",
    "    \\text{Age Adjustment} = \\begin{cases} \n",
    "        0.003 * (29 - \\text{Age}) & \\text{Age} > 29\\\\\n",
    "        0.006 * (29 - \\text{Age}) & \\text{Age} <= 29\n",
    "    \\end{cases}    \n",
    "$$\n",
    "\n",
    "The final projection is given by:\n",
    "$$\n",
    "    \\text{HR Projection} = \\text{Projected PA} \\cdot \\text{Projected HR Rate} \\cdot (1 + \\text{Age Adjustment})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trout_age = 27\n",
    "age_adjust = 0.003 * (29 - trout_age) if trout_age > 29 \\\n",
    "    else 0.006 * (29 - trout_age)\n",
    "trout_HR_aged_projection = trout_HR_projection * (1 + age_adjust)\n",
    "trout_HR_aged_projection"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
