{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking Systems\n",
    "\n",
    "Every year, Division 1 college football is consumed with debate over the team rankings.  Starting in 1998, these rankings directly impacted which teams would face off in the BCS Championship game.  Starting in 2014, the rankings impacted the selection of the top 4 teams for the BCS playoff.  College football is a perfect example of the need for a ranking system but the approaches laid out in this notebook are potentially universal: they can be applied to any sport.  \n",
    "\n",
    "It is important to clarify two terms that will be used throughout: _rating_ and _ranking_.  A _rating_ is a numeric value that quantifies the performance of a player or team.  A _ranking_ is an ordering of the players/teams according to a rating metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../../utils/notebook_setup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incomplete Tournaments\n",
    "\n",
    "In the mathematics of graphs (not plots but networks of nodes and edges), a _Complete Tournament_ is what is commonly known as _Round Robin_: every team plays every other team.  In the NBA and the NHL, each pair of teams play at least twice.  In MLB, a team is only guaranteed to play teams within its own league.  And within the NFL, a team is only guaranteed to play teams within its division.\n",
    "\n",
    "Division 1A college football has 129 teams.  They play 12 games each.  This is about as far from a Round Robin as it gets.  Given the diverse performance and relative lack of games played, how do we build a ranking under these conditions?\n",
    "\n",
    "This notebook will cover three approaches:\n",
    "+ Elo\n",
    "+ Matrix/Regression\n",
    "+ Graph/Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Elo Rating\n",
    "\n",
    "Suppose we have two teams, $A$ and $B$, with ratings $R_A$ and $R_B$, respectively.\n",
    "\n",
    "### Expected Outcome\n",
    "With a win as 1 and a loss as 0, we can compute the expected outcome for $A$ (also a probability of winning),\n",
    "$$\n",
    "    E_A = \\frac 1 {1 + 10^{(R_B - R_A)/400}} = \\frac{Q_A}{Q_A + Q_B}\n",
    "$$\n",
    "and the expected outcome for $B$,\n",
    "$$\n",
    "    E_B = \\frac 1 {1 + 10^{(R_A - R_B)/400}} = \\frac{Q_B}{Q_A + Q_B} = 1 - E_A\n",
    "$$\n",
    "where $Q_A = 10^{R_A/400}$ and $Q_B = 10^{R_B/400}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elo_prediction(elo_rank_A, elo_rank_B, base=10, scale=400):\n",
    "    q_A = base**(elo_rank_A / scale)\n",
    "    q_B = base**(elo_rank_B / scale)\n",
    "    e_A = q_A / (q_A + q_B)\n",
    "    return e_A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = elo_prediction(1500, 1500)\n",
    "print(f\"Prob. of A winning: {p:.3f}\")\n",
    "print(f\"Prob. of B winning: {1 - p:.3f}\")\n",
    "print(f\"Odds for A: {p / (1 - p):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = elo_prediction(1600, 1500)\n",
    "print(f\"Prob. of A winning: {p:.3f}\")\n",
    "print(f\"Prob. of B winning: {1 - p:.3f}\")\n",
    "print(f\"Odds for A: {p / (1 - p):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = elo_prediction(1900, 1500)\n",
    "print(f\"Prob. of A winning: {p:.3f}\")\n",
    "print(f\"Prob. of B winning: {1 - p:.3f}\")\n",
    "print(f\"Odds for A: {p / (1 - p):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = elo_prediction(1500, 1900)\n",
    "print(f\"Prob. of A winning: {p:.3f}\")\n",
    "print(f\"Prob. of B winning: {1 - p:.3f}\")\n",
    "print(f\"Odds for A: {p / (1 - p):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updated Ranking\n",
    "\n",
    "For outcomes $S_A$ and $S_B$ (we'll assume one is a win (1) and one is a loss (0)), the updated ratings are,\n",
    "\\begin{gather*}\n",
    "    R_A^\\prime = R_A + K \\times (S_A - E_A),\\\\\n",
    "    R_B^\\prime = R_B + K \\times (S_B - E_B),\n",
    "\\end{gather*}\n",
    "where $K$ is a constant chosen for the rating model that quantifies the impact of a new result on the rating.\n",
    "\n",
    "A common value for $K$ is 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elo_update(rank_old, score, expected_score, k):\n",
    "    return rank_old + k * (score - expected_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_A = 1500\n",
    "R_B = 1500\n",
    "Outcome = 1\n",
    "E_A = elo_prediction(R_A, R_B)\n",
    "K = 32\n",
    "\n",
    "R_A_prime = elo_update(R_A, Outcome, E_A, K)\n",
    "print(f\"Old Rating: {R_A:.3f}  New Rating: {R_A_prime:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update rating\n",
    "R_A = R_A_prime\n",
    "# new outcome prediction\n",
    "E_A = elo_prediction(R_A, R_B)\n",
    "\n",
    "R_A_prime = elo_update(R_A, Outcome, E_A, K)\n",
    "print(f\"Old Rating: {R_A:.3f}  New Rating: {R_A_prime:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Order Matters\n",
    "Elo Rating favors recent results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A beats B, then loses to B\n",
    "R_A = 1500\n",
    "R_B = 1500\n",
    "E_A = E_B = .5\n",
    "K = 32\n",
    "\n",
    "# first match\n",
    "Outcome = 1\n",
    "R_A_prime = elo_update(R_A, Outcome, E_A, K)\n",
    "R_B_prime = elo_update(R_B, 1 - Outcome, E_B, K)\n",
    "\n",
    "# second match\n",
    "E_A_prime = elo_prediction(R_A_prime, R_B_prime)\n",
    "E_B_prime = 1 - E_A_prime\n",
    "Outcome = 0\n",
    "R_A_prime2 = elo_update(R_A_prime, Outcome, E_A_prime, K)\n",
    "R_B_prime2 = elo_update(R_B_prime, 1 - Outcome, E_B_prime, K)\n",
    "\n",
    "print(R_A_prime2, R_B_prime2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A loses to B, then beats B\n",
    "R_A = 1500\n",
    "R_B = 1500\n",
    "E_A = E_B = .5\n",
    "K = 32\n",
    "\n",
    "# first match\n",
    "Outcome = 0\n",
    "R_A_prime = elo_update(R_A, Outcome, E_A, K)\n",
    "R_B_prime = elo_update(R_B, 1 - Outcome, E_B, K)\n",
    "\n",
    "# second match\n",
    "E_A_prime = elo_prediction(R_A_prime, R_B_prime)\n",
    "E_B_prime = 1 - E_A_prime\n",
    "Outcome = 1\n",
    "R_A_prime2 = elo_update(R_A_prime, Outcome, E_A_prime, K)\n",
    "R_B_prime2 = elo_update(R_B_prime, 1 - Outcome, E_B_prime, K)\n",
    "\n",
    "print(R_A_prime2, R_B_prime2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fake Data\n",
    "\n",
    "We'll try out Elo on a small fake dataset to show how the ratings can be turned into rankings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_games = pd.read_csv('fake_cfb_scores.csv')\n",
    "fake_games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EloRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience_topic import elo_rank\n",
    "\n",
    "fake_ranking = elo_rank(fake_games)\n",
    "fake_ranking.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real CFB Data\n",
    "\n",
    "Now we'll use the actual results from the 2018 season. We drop the NESCAC schools because they only play each other and are separate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cfb_games = pd.read_csv('cfb_scores_2018.csv', parse_dates=['Date'])\n",
    "\n",
    "nescac_schools = [\n",
    "    'bates', 'amherst', 'wesleyan', 'middlebury', 'colby',\n",
    "    'trinity ct', 'hamilton', 'tufts', 'bowdoin', 'williams']\n",
    "\n",
    "\n",
    "nescac_mask = cfb_games['Away Team'].isin(nescac_schools) | \\\n",
    "    cfb_games['Home Team'].isin(nescac_schools)\n",
    "date_mask = cfb_games.Date <= \"2018-12-10\"\n",
    "\n",
    "cfb_games = cfb_games.loc[date_mask & ~nescac_mask].copy()\n",
    "\n",
    "cfb_games.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Ranking: Win %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience_topic import win_pct_rank\n",
    "\n",
    "rankings = pd.DataFrame()\n",
    "rankings['Win %'] = win_pct_rank(cfb_games)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Who??\n",
    "\n",
    "Lower division schools will pollute ranking systems.  Ideally, the ranking would handle these lower level teams but it can be hard, especially when they win every game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankings['Elo'] = elo_rank(cfb_games)\n",
    "rankings.sort_values(by='Elo', ascending=False).\\\n",
    "    head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restrict to only FBS\n",
    "\n",
    "From now on, we'll restrict to FBS only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbs_teams = open('d1ateams.txt').read().splitlines()\n",
    "rankings.loc[fbs_teams].\\\n",
    "    sort_values(by='Elo', ascending=False).\\\n",
    "    head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbs_mask = cfb_games['Away Team'].isin(fbs_teams) & \\\n",
    "    cfb_games['Home Team'].isin(fbs_teams)\n",
    "\n",
    "fbs_games = cfb_games.loc[fbs_mask].copy()\n",
    "\n",
    "fbs_rankings = pd.DataFrame()\n",
    "fbs_rankings['Win %'] = win_pct_rank(cfb_games)\n",
    "\n",
    "fbs_rankings['Elo'] = elo_rank(fbs_games)\n",
    "fbs_rankings.sort_values(by='Elo', ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Matrix/Regression Rankings\n",
    "\n",
    "Matrix or Regression approaches utilize a matrix equation or a regression equation to produce a rating.  There are many approaches, two of which are covered here: Massey and Bradley-Terry.  Two other matrix methods are the Colley method and the Keener method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Massey Method\n",
    "\n",
    "The Massey method sets up a very simple regression equation:\n",
    "\\begin{align*}\n",
    "    \\text{Home Score - Away Score} \n",
    "        & = \\text{Home-Field Advantage} + \\sum_{\\text{All Teams}} \\text{Team $i$ Rating} \\times \\text{Team $i$ is at Home} \\\\\n",
    "    & \\quad - \\sum_{\\text{All Teams}} \\text{Team $i$ Rating} \\times \\text{Team $i$ is Away}\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fake Data\n",
    "\n",
    "Let's run the Massey method on our fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_games = pd.read_csv('fake_cfb_scores.csv')\n",
    "fake_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience_topic import massey_matrix_equation, massey_rank\n",
    "\n",
    "Massey_matrix, score_diff = massey_matrix_equation(fake_games)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the structure of the Massey matrix corresponds to the above regression equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Massey_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "massey_fake_ranking = massey_rank(fake_games)\n",
    "massey_fake_ranking.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real Data\n",
    "\n",
    "We'll append the Massey ranking onto our previous table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbs_rankings['Massey'] = massey_rank(fbs_games)\n",
    "fbs_rankings.sort_values('Massey', ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bradley-Terry Logistic Model\n",
    "\n",
    "The Bradley-Terry method sets up a very _Logistic_ regression equation:\n",
    "\\begin{align*}\n",
    "    \\text{Log Odds for Home Team} \n",
    "        & = \\text{Home-Field Advantage} + \\sum_{\\text{All Teams}} \\text{Team $i$ Rating} \\times \\text{Team $i$ is at Home} \\\\\n",
    "        & \\quad -\\sum_{\\text{All Teams}} \\text{Team $i$ Rating} \\times \\text{Team $i$ is Away}\n",
    "\\end{align*}\n",
    "\n",
    "The log odds aren't observable though: we only see a team win or lose.  The objective of the Logistic Regression is to find a set of ratings where the ratings predict a high log odds for games the home team won and a low log odds for the games the home team lost.\n",
    "\n",
    "Another way to think about it is through the logistic function:\n",
    "$$\n",
    "    \\text{Probability Home Team Wins} = \\frac{1}{1 + \\exp(-\\text{Log Odds for Home Team})}\n",
    "$$\n",
    "As the log odds goes to infinity, the probability the home team wins goes to 1.  As the log odds goes to negative infinity, the probability the home team wins goes to 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience_topic import bradleyterry_logistic_model, bradleyterry_rank\n",
    "\n",
    "bradleyterry_matrix, outcomes = bradleyterry_logistic_model(fake_games)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bradley-Terry matrix is the same as the Massey matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bradleyterry_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we only track wins or losses for the home team (1 is a win)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bradley-Terry and Real Data\n",
    "\n",
    "We'll append the Bradley-Terry ranking onto our previous table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbs_rankings['BradleyTerry'] = bradleyterry_rank(fbs_games)\n",
    "fbs_rankings.sort_values('BradleyTerry', ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Penalized Logistic Regression\n",
    "\n",
    "SEC West teams (and likely all Alabama opponents) are getting rated super high.  Why? Alabama won all their games and those teams won a lot of games.  If the model gives Alabama a huge rating, then the other schools can get high ratings which won't go against the fact that Alabama beat them.\n",
    "\n",
    "Basically, this model is overfitting and we need to penalize the ratings so they aren't so large.  We used a penalized Bradley-Terry model for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience_topic import bradleyterry_penalized_rank\n",
    "\n",
    "fbs_rankings['BradleyTerry_penalized'] = bradleyterry_penalized_rank(fbs_games)\n",
    "fbs_rankings.sort_values('BradleyTerry_penalized', ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Graph/Network Rankers\n",
    "\n",
    "A Graph is a mathematical object that convery relations through the concept of nodes and edges.  The Python package `networkx` is incredibly useful for working with graphs.  It helps to visualize the graphs.\n",
    "\n",
    "We're going to consider random walk/Markov chain ranking systems that utilize the graph structure to deduce the strengths of the teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from datascience_topic import scores_to_network\n",
    "\n",
    "graph = scores_to_network(fake_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_circular(graph, with_labels=True, node_color='C1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Basics of the PageRank Random Walker Model\n",
    "\n",
    "PageRank was one of the big innovation from the founders of Google, though the original ideas for the problem go back quite a ways.  PageRank is named after Larry Page from work with Sergey Brin at Stanford.  The chief idea behind PageRank is using a graph like above to quantify the importance of web pages or teams according to how often a random walker would visit that page.  Here's how that works:\n",
    "\n",
    "**The Random Walker**\n",
    "\n",
    "Imagine a walker who is traveling on the above graph moving from team to team.  This walker will only move randomly though and only in the proper direction of the directed edges (note how the edges are actually arrows).  If the walker is at Delaware St, there are 4 possible edges to leave on.  The walker will pick 1 at random and move to along that edge to the next team.  If the walker is at Florida, there are two edges out: Cal and Alabama.  A problem occurs if the walker reaches Alabama: there are no ways out (Alabama beat everyone).  \n",
    "\n",
    "**Random Jump**\n",
    "\n",
    "In order to make the random walking work, the walker on occasion will jump to a random team on the graph instead of traversing the graph.  How often will this happen?  That's a model choice but a typical value is about 15% of the time.  This random jump will allow the walker to leave Alabama eventually and keep walking.\n",
    "\n",
    "**The Ranking**\n",
    "\n",
    "Now imagine the walker keeps walking and walking.  If we keep track of how often the walker visits each team, then the proportion of visits gives us a ranking: the more the walker visits a team, the more important or powerful that team is in drawing in the walker, and hence the higher its ranking should be. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience_topic import PageRankWalker\n",
    "\n",
    "pr_walker = PageRankWalker(graph)\n",
    "pr_walker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_walker.walk()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Infinite Steps\n",
    "\n",
    "Ideally, we'd make the walker go forever.  For small graphs, the ranking stabilizes relatively quickly.  For large graphs (like a full slate of CFB games or the internet), the random walker is rendered merely an exercise for explaining the concept.  Mathematically, we solve a eigenvalue problem using linear algebra to produce the steady-state, long-run visit probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_walker.walk(num_steps=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PageRank for Real Data\n",
    "\n",
    "Let's apply PageRank to rank CFB Games.  First we need to convert the scores to a network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfb_graph = scores_to_network(cfb_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience_topic import draw_graph\n",
    "\n",
    "all_divs = dict(\n",
    "    FBS=open('d1ateams.txt').read().splitlines(),\n",
    "    FCS=open('d1aateams.txt').read().splitlines(),\n",
    "    D2=open('d2teams.txt').read().splitlines(),\n",
    "    D3=open('d3teams.txt').read().splitlines(),\n",
    "    NAIA=open('naia_other.txt').read().splitlines()\n",
    ")\n",
    "\n",
    "draw_graph(cfb_graph, divisions=all_divs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience_topic import page_rank\n",
    "\n",
    "rankings['PageRank'] = page_rank(cfb_graph)\n",
    "rankings.sort_values('PageRank', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Division 1 Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcs_teams = all_divs['FCS']\n",
    "\n",
    "d1_teams = {\n",
    "    'FBS': fbs_teams, \n",
    "    'FCS': fcs_teams\n",
    "}\n",
    "\n",
    "d1_graph = scores_to_network(cfb_games, divisions=d1_teams)\n",
    "draw_graph(d1_graph, divisions=d1_teams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FBS Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbs_dict = {'FBS': fbs_teams}\n",
    "\n",
    "fbs_graph = scores_to_network(cfb_games, divisions=fbs_dict)\n",
    "draw_graph(fbs_graph, divisions=fbs_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Texas and Purdue!?!?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbs_rankings['PageRank'] = page_rank(fbs_graph)\n",
    "fbs_rankings.sort_values('PageRank', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MonkeyRank\n",
    "\n",
    "PageRank has a fundamental problem when it comes to ranking CFB teams.  Consider a team like Ohio State that only loses once: then when the walker arrives at Ohio State (which is often because OSU won a bunch of games), then unless the walker randomly jumps somewhere they are guaranteed to walk to Purdue next because Ohio State lost only one game, to Purdue.\n",
    "\n",
    "A different approach developed by a friend of mine tweaks the approach of the walker (and instead thinks of it as a Monkey making picks).  The idea is that the monkey chooses _any_ opponent at random and then flips a coin to decide if he should switch from favoring the current team to favoring the opponent.  If the coin comes up heads, the monkey will favor the actual winner of the matchup.  Otherwise, he will favor the loser.  The probability of heads coming up is $p$ and is a modeling choice.  The frequency over time that the monkey favors teams determines the ranking.\n",
    "\n",
    "The long-run steady state MonkeyRank can also be computed through solving a linear algebra problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience_topic import monkey_rank\n",
    "\n",
    "fbs_rankings['MonkeyRank'] = monkey_rank(fbs_graph, winner_probability=.85)\n",
    "fbs_rankings.sort_values('MonkeyRank', ascending=False).head(25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
